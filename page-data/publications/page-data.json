{"componentChunkName":"component---src-pages-publications-index-js","path":"/publications/","result":{"data":{"publications":{"nodes":[{"id":"f8fffec9-b374-5835-8e85-0ec13324e466","authors":[{"id":"530344ac-fbae-5332-b90f-066e12de1a9b","name":"Francesco","surname":"Vigni","web":"https://scholar.google.com/citations?user=ksO3xN0AAAAJ&hl=en","slug":"francesco-vigni"},{"id":"d2703613-4de5-5cca-8746-e3d741cc5d92","name":"Antonio","surname":"Andriella","web":"https://antonioandriella.com","slug":"antonio-andriella"},{"id":"66cc5e18-c2d7-560d-a550-355e5fa74476","name":"Silvia","surname":"Rossi","web":"https://scholar.google.com/citations?user=Q_F1-QIAAAAJ&hl=en&oi=ao","slug":"silvia-rossi"}],"abstract":"The ability to impact the attitudes and behaviours of others is a key aspect of human-human interaction. The same capability is a desideratum in human-robot interaction, when it can have an impact on healthy behaviours. The robot's interaction style plays a significant role in achieving effective communication, leading to better outcomes, improved user experience, and overall enhanced robot performance. Nonetheless, little is known about how different robots' communication styles impact users' performance and decision-making. In this article, we build upon previous work, in which a robot was endowed with two personality behavioural patterns: one more antagonist and other-comparative and the other one more agreeable and self-comparative. We conducted a user study where N=66 participants played a game with a robot displaying the two multimodal communication styles. Our results indicated that i) participants' decision-making was not influenced by the designed robot's communication styles, ii) participants who interacted with the agreeable robot performed better in the game, and iii) the more participants are knowledgeable about robots, the lower they performed in the game.","slug":"sweet-robot","tags":["social robot","non-verbal cues","roman","robot game"],"location":"Busan, Korea","title":"Sweet Robot O’Mine - How a Cheerful Robot Boosts Users' Performance in a Game Scenario","url":"","venue":"32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN 2023)","date":"Aug 2023"},{"id":"9e66b59b-c59d-5ee4-af0d-30ee72c87895","authors":[{"id":"530344ac-fbae-5332-b90f-066e12de1a9b","name":"Francesco","surname":"Vigni","web":"https://scholar.google.com/citations?user=ksO3xN0AAAAJ&hl=en","slug":"francesco-vigni"},{"id":"66cc5e18-c2d7-560d-a550-355e5fa74476","name":"Silvia","surname":"Rossi","web":"https://scholar.google.com/citations?user=Q_F1-QIAAAAJ&hl=en&oi=ao","slug":"silvia-rossi"}],"abstract":"The growing deployment of robots in social contexts implies the need to model their behaviour as social agents. In this context, the way a robot approaches a user and eventually engages in an interaction is a crucial aspect to take into account for the acceptance of these tools.\n In this work, we explore how the approaching policy and gaze behaviours can influence the perceived intention to interact before the interaction starts. The conducted user study highlights the importance of the robot’s gaze behaviour when approaching a human with respect to its approaching behaviour. In particular, if the robot moves in the surroundings of a human, even not straightforward in their direction, but locks the gaze at them, the intention to interact is recognised clearer and faster with respect to the direct approaching of the user but with an adverse gaze.","slug":"icsr-approach","tags":["approach","non-verbal cues","icsr"],"location":"Florence, Italy","title":"Exploring Non-Verbal Strategies for Initiating an HRI","url":"https://link.springer.com/chapter/10.1007/978-3-031-24667-8_25","venue":"14th International Conference on Social Robotics (ICSR 2022)","date":"Feb 2023"},{"id":"04dffc2b-2171-590e-ab4a-7e97fcdc7026","authors":[{"id":"530344ac-fbae-5332-b90f-066e12de1a9b","name":"Francesco","surname":"Vigni","web":"https://scholar.google.com/citations?user=ksO3xN0AAAAJ&hl=en","slug":"francesco-vigni"},{"id":"fd22eb6f-1c56-52c1-8a88-91b404168e24","name":"Alessandra","surname":"Rossi","web":"https://scholar.google.com/citations?hl=en&user=ETBNEJ0AAAAJ","slug":"alessandra-rossi"},{"id":"8fbee7fe-3f6a-536e-8db2-71d4a70af0f8","name":"Linda","surname":"Miccio","web":null,"slug":"linda-miccio"},{"id":"66cc5e18-c2d7-560d-a550-355e5fa74476","name":"Silvia","surname":"Rossi","web":"https://scholar.google.com/citations?user=Q_F1-QIAAAAJ&hl=en&oi=ao","slug":"silvia-rossi"}],"abstract":"Non-anthropomorphic robots have issues in conveying internal state during a Human-Robot Interaction (HRI). A possible approach is to let robots communicate their states or intentions through emotions. However, the robot’s emotional responses are not always clearly identified by people, and it is also difficult to identify which and how many cues are most relevant in affecting people’s ability of recognition of robots’ emotions during the ongoing interaction. We involved 102 participants in an online questionnaire-based study where they rated the robot’s behaviours, designed in terms of colours, movements and sounds, according to the perceived emotions in order to identify the cues to be used for making robots more legible. The results suggest that emotional transparency can benefit from multimodal interaction. Our results underline that single modes can be capable of conveying effectively the desired emotion, and little benefit is obtained by the use of additional modes that may be not necessarily noticed by the users.","slug":"icsr-emotions","tags":["emotions","non-humanoid","icsr"],"location":"Florence, Italy","title":"On The Emotional Transparency of a Non-Humanoid Social Robot","url":"https://link.springer.com/chapter/10.1007/978-3-031-24667-8_26","venue":"14th International Conference on Social Robotics (ICSR 2022)","date":"Feb 2023"},{"id":"6b5d34de-743c-5874-89f0-8dac67b103fd","authors":[{"id":"84456754-6387-59b9-9474-36214e44e4a1","name":"Georgios","surname":"Angelopoulos","web":"https://scholar.google.com/citations?hl=en&user=C2jDeBkAAAAJ","slug":"georgios-angelopoulos"},{"id":"530344ac-fbae-5332-b90f-066e12de1a9b","name":"Francesco","surname":"Vigni","web":"https://scholar.google.com/citations?user=ksO3xN0AAAAJ&hl=en","slug":"francesco-vigni"},{"id":"fd22eb6f-1c56-52c1-8a88-91b404168e24","name":"Alessandra","surname":"Rossi","web":"https://scholar.google.com/citations?hl=en&user=ETBNEJ0AAAAJ","slug":"alessandra-rossi"},{"id":"418cd9e7-749a-5b75-911d-311dcd1efe22","name":"Giuseppina","surname":"Russo","web":null,"slug":"giuseppina-russo"},{"id":"34d71983-6dcf-5bff-9a67-560576c9399f","name":"Mario","surname":"Turco","web":null,"slug":"mario-turco"},{"id":"66cc5e18-c2d7-560d-a550-355e5fa74476","name":"Silvia","surname":"Rossi","web":"https://scholar.google.com/citations?user=Q_F1-QIAAAAJ&hl=en&oi=ao","slug":"silvia-rossi"}],"abstract":"When navigating in a shared environment, the extent to which robots are able to effectively use signals for coordinating with human behaviors can ameliorate dissatisfaction and increase acceptance. In this paper, we present an online video study to investigate whether familiar acoustic signals can improve the legibility of a robot’s navigation behavior. We collected the responses of 120 participants to evaluate their perceptions of a robot that communicates with one of the three used non-verbal navigational cues (an acoustic signal, an acoustic in pair with a visual signal, and a dissimilar frequency acoustic signal). Our results showed a significant legibility improvement when the robot used both light and acoustic signals to communicate its intentions compared to using only the same acoustic sound. Additionally, our findings highlighted that people also perceived differently the robot’s intentions when they were expressed through two frequencies of the mere sound. The results of this work suggest a paradigm that can help the development of mobile service robots in public spaces.","slug":"roman-roomba","tags":["non-verbal cues","non-humanoid","roman"],"location":"Naples, Italy","title":"Familiar Acoustic Cues for Legible Service Robots","url":"https://ieeexplore.ieee.org/document/9900699","venue":"31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN 2022)","date":"Aug 2022"},{"id":"d889cadc-54e5-5ff5-b7b9-4976e60262ac","authors":[{"id":"530344ac-fbae-5332-b90f-066e12de1a9b","name":"Francesco","surname":"Vigni","web":"https://scholar.google.com/citations?user=ksO3xN0AAAAJ&hl=en","slug":"francesco-vigni"},{"id":"97eb6e91-d8fb-58fa-8c20-9453cc47f704","name":"Espen","surname":"Knoop","web":null,"slug":"espen-knopp"},{"id":"ae72bbfe-a006-5654-bfd1-64ad3d9f7d2d","name":"Domenico","surname":"Prattichizzo","web":"https://scholar.google.com/citations?hl=en&user=mMjWcPAAAAAJ","slug":"domenico-prattichizzo"},{"id":"ca3ba40c-746d-5619-8c58-da410e7fd96b","name":"Monica","surname":"Malvezzi","web":"https://scholar.google.com/citations?user=M0NWWgcAAAAJ&hl=en","slug":"monica-malvezzi"}],"abstract":"In this letter, we investigate the role of haptic feedback in human–robot handshaking by comparing different force controllers. The basic hypothesis is that in human handshaking force control there is a balance between an intrinsic (open-loop) and extrinsic (closed-loop) contributions. We use an underactuated anthropomorphic robotic hand, the Pisa/IIT hand, instrumented with a set of pressure sensors estimating the grip force applied by humans. In a first set of experiments, we ask subjects to mimic a given force profile applied by the robot hand, to understand how human perceive and are able to reproduce a handshaking force. Using the obtained results, we implement three different handshaking controllers, in which we varied the intrinsic and extrinsic contributions and in a second set of experiments, we ask participants to evaluate them in a user study. We show that a sensorimotor delay mimicking the reaction time of the central nervous system is beneficial for making interactions more human-like. Moreover, we demonstrate that humans exploit closed-loop control for handshaking. By varying the controller we show that we can change the perceived handshake quality and also influence personality traits attributed to the robot. ","slug":"icra-handshake","tags":["handshake","icra","non-verbal cues"],"location":"Montreal, Canada","title":"The Role of Closed-Loop Hand Control in Handshaking Interactions","url":"https://ieeexplore.ieee.org/document/8613850","venue":"IEEE International Conference on Robotics and Automation (ICRA 2019)","date":"Jan 2019"}]},"tags":{"group":[{"fieldValue":"approach"},{"fieldValue":"emotions"},{"fieldValue":"handshake"},{"fieldValue":"icra"},{"fieldValue":"icsr"},{"fieldValue":"non-humanoid"},{"fieldValue":"non-verbal cues"},{"fieldValue":"robot game"},{"fieldValue":"roman"},{"fieldValue":"social robot"}],"totalCount":5},"misc":{"nodes":[{"id":"02e501fb-0f06-5537-b838-fb5f985924ca","title":"An Interaction-centric Approach to Metrics in Social HRI","date":"Mar 2023","slug":"hri2023","attach":{"name":"nofile","publicURL":"/static/d41d8cd98f00b204e9800998ecf8427e/nofile.txt"},"type":"Workshop paper","authors":[{"id":"530344ac-fbae-5332-b90f-066e12de1a9b","name":"Francesco","surname":"Vigni","web":"https://scholar.google.com/citations?user=ksO3xN0AAAAJ&hl=en"},{"id":"66cc5e18-c2d7-560d-a550-355e5fa74476","name":"Silvia","surname":"Rossi","web":"https://scholar.google.com/citations?user=Q_F1-QIAAAAJ&hl=en&oi=ao"}]},{"id":"2a81d424-def8-5ae9-a49c-07d324669b3b","title":"A Closed Loop Approach to Human-Robot Handshake","date":"Oct 2018","slug":"master-thesis","attach":{"name":"msc_thesis","publicURL":"/static/0adc05687479b2403be85552d595a42c/msc_thesis.pdf"},"type":"Master Thesis","authors":[{"id":"530344ac-fbae-5332-b90f-066e12de1a9b","name":"Francesco","surname":"Vigni","web":"https://scholar.google.com/citations?user=ksO3xN0AAAAJ&hl=en"},{"id":"ae72bbfe-a006-5654-bfd1-64ad3d9f7d2d","name":"Domenico","surname":"Prattichizzo","web":"https://scholar.google.com/citations?hl=en&user=mMjWcPAAAAAJ"},{"id":"ca3ba40c-746d-5619-8c58-da410e7fd96b","name":"Monica","surname":"Malvezzi","web":"https://scholar.google.com/citations?user=M0NWWgcAAAAJ&hl=en"},{"id":"97eb6e91-d8fb-58fa-8c20-9453cc47f704","name":"Espen","surname":"Knoop","web":null}]},{"id":"506eaa01-0b46-51a9-a997-0ce5ce3cdd24","title":"Analisi e confronti di strategie di trading basate sul trend following","date":"Oct 2015","slug":"bachelor-thesis","attach":{"name":"bsc_thesis","publicURL":"/static/8bb932a187a0be98e96fb0da6ec11880/bsc_thesis.pdf"},"type":"Bachelor Thesis","authors":[{"id":"530344ac-fbae-5332-b90f-066e12de1a9b","name":"Francesco","surname":"Vigni","web":"https://scholar.google.com/citations?user=ksO3xN0AAAAJ&hl=en"},{"id":"82018095-0a35-5ee8-86c4-f76d882b995b","name":"Antonio","surname":"Vicino","web":"https://scholar.google.com/citations?user=Z1Mf9KwAAAAJ&hl=en"}]}]}},"pageContext":{}},"staticQueryHashes":["3248652660","3649515864"],"slicesMap":{}}